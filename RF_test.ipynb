{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import urllib.request\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import sklearn\n",
    "import joblib\n",
    "import hdf5storage\n",
    "import itertools\n",
    "import h5py\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import seaborn as sns\n",
    "from tsmoothie.utils_func import sim_randomwalk\n",
    "from tsmoothie.smoother import LowessSmoother\n",
    "from tsmoothie.utils_func import sim_seasonal_data\n",
    "from tsmoothie.smoother import DecomposeSmoother\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from data_cul import  merge_data\n",
    "import joblib\n",
    "\n",
    "plt.rcParams['font.sans-serif']=['SimHei']  # 用来正常显示中文标签\n",
    "plt.rcParams['axes.unicode_minus']=False  # 用来正常显示负号"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth(data):\n",
    "    # operate smoothing\n",
    "    #参数整定\n",
    "    smoother = DecomposeSmoother(smooth_type='lowess', periods=50,\n",
    "                                smooth_fraction=0.2)\n",
    "    smoother.smooth(data)\n",
    "    low, up = smoother.get_intervals('sigma_interval')\n",
    "    return smoother.smooth_data # 处理后的数据\n",
    "\n",
    "def cul_data(path):\n",
    "    \"\"\"\n",
    "    cul_data处理\n",
    "\n",
    "    path:  数据所在的文件路径\n",
    "\n",
    "    return: 返回值是处理后的结果\n",
    "    \"\"\"\n",
    "    num = int(path[-5])  # 读取文件命名\n",
    "    f = hdf5storage.loadmat(path)\n",
    "    if num == 0:\n",
    "        element_name = 'MM_multi_MA_'\n",
    "    else:\n",
    "        element_name = 'MM_multi_MA_0'\n",
    "\n",
    "    src_data = np.array(f[element_name + str(num)])\n",
    "\n",
    "    ## 阵元归一\n",
    "    divisor = src_data[0,:]\n",
    "\n",
    "    divisor = divisor[np.newaxis,:]\n",
    "    # print(divisor.shape)\n",
    "\n",
    "    temp_data = src_data / divisor\n",
    "\n",
    "    num_cols = temp_data.shape[1]\n",
    "    k = 1000\n",
    "    random_cols = np.random.choice(num_cols, k, replace=False)\n",
    "    sm_data = temp_data[:,random_cols]\n",
    "    # return sm_data\n",
    "    return temp_data\n",
    "\n",
    "def add_label(data, label):\n",
    "    '''\n",
    "    add_label:\n",
    "\n",
    "    data:原始数据\n",
    "\n",
    "    label: 标签\n",
    "    \n",
    "    return: \n",
    "    '''\n",
    "    news_row = np.array([label] *data.shape[1])\n",
    "\n",
    "    arr = np.vstack((data, news_row))\n",
    "    \n",
    "    return arr\n",
    "\n",
    "def handle_data():\n",
    "    '''\n",
    "        return: 整个数据集 滤波后的数据\n",
    "    '''\n",
    "    path = ['../data/val_All_MM_MA_0.mat', '../data/val_All_MM_MA_04.mat', '../data/val_All_MM_MA_07.mat']\n",
    "\n",
    "    k = 0\n",
    "    all_data_test = []\n",
    "    for i in path:\n",
    "        temp_data = cul_data(i)\n",
    "        # temp_data = smooth(temp_data)\n",
    "        all_data_test.append(add_label(temp_data, k))\n",
    "        k = k+1\n",
    "    return all_data_test\n",
    "\n",
    "def merge_data(data):\n",
    "    '''\n",
    "    data: 传入列表数据\n",
    "    return: 合并后的数组 arr\n",
    "    '''\n",
    "    k = 10000  ## 取前一万个数据\n",
    "\n",
    "    num_cols = data[0].shape[1]\n",
    "\n",
    "    random_cols = np.random.choice(num_cols, k, replace=False)\n",
    "    temp_data = data[0][:,random_cols]\n",
    "\n",
    "    for i in range(1, len(data)):\n",
    "        num_cols = data[i].shape[1]\n",
    "\n",
    "        random_cols = np.random.choice(num_cols, k, replace=False)\n",
    "        merge_arr = np.concatenate((temp_data, data[i][:,random_cols]), axis=1)\n",
    "        temp_data = merge_arr\n",
    "\n",
    "    return temp_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_val_data = handle_data()\n",
    "\n",
    "all_data = merge_data(temp_val_data)\n",
    "\n",
    "Labels = all_data[-1,:].T\n",
    "\n",
    "# all_Features = all_data[:-1, :]\n",
    "all_Features = smooth(all_data[:-1, :1000])\n",
    "\n",
    "i = 1000\n",
    "while i < all_data.shape[1] :\n",
    "    temp_Features = smooth(all_data[:-1,i:i+1000])\n",
    "    all_Features = np.concatenate((all_Features, temp_Features),axis=1)\n",
    "    i += 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:59.717\n"
     ]
    }
   ],
   "source": [
    "Features = all_Features.T\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(Features, Labels, test_size=0.2, random_state=42)\n",
    "\n",
    "rcf_test = joblib.load(\"./model/rfc_3_model-0.942.model\")\n",
    "\n",
    "y_pred = rcf_test.predict(X_test)\n",
    "\n",
    "accuracy = np.mean(y_pred == y_test)\n",
    "\n",
    "print(\"Accuracy:{:.3f}\".format(accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1989,    9,    4],\n",
       "       [1708,   36,  252],\n",
       "       [   4,  423, 1575]], dtype=int64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "conf_matrix"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lqpytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
